{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fdbc5a0ed9b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Connecting to the Website\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeodataframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_postgis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopandas\\geoseries.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseGeometry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyproj\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyproj\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_proj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatadir\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyproj_datadir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0m_proj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import shapefile\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb; sb.set()\n",
    "import geopandas as gpd\n",
    "\n",
    "# Connecting to the Website\n",
    "def pgconnect():\n",
    "    # please replace <your_unikey> and <your_SID> with your own details\n",
    "    YOUR_UNIKEY = 'wtan2604'#'<your_unikey>'\n",
    "    YOUR_PW     = '480570594'#'<your_SID>'\n",
    "    try: \n",
    "        conn = psycopg2.connect(host='soit-db-pro-2.ucc.usyd.edu.au',\n",
    "                                database='y19s1d2901_'+YOUR_UNIKEY,\n",
    "                                user='y19s1d2901_'+YOUR_UNIKEY,\n",
    "                                password=YOUR_PW,\n",
    "                                options=f'-c search_path=cyclability')\n",
    "        print('connected')\n",
    "    except Exception as e:\n",
    "        print(\"unable to connect to the database\")\n",
    "        print(e)\n",
    "        return None\n",
    "    return conn\n",
    "\n",
    "\n",
    "def pgexec(conn, sqlcmd, args, msg, silent=False):\n",
    "    retval = False\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            try:\n",
    "                if args is None:\n",
    "                    cur.execute(sqlcmd)\n",
    "                else:\n",
    "                    cur.execute(sqlcmd, args)\n",
    "                if silent == False:\n",
    "                    print(\"success: \" + msg)\n",
    "                retval = True\n",
    "            except Exception as e:\n",
    "                if silent == False:\n",
    "                    print(\"db error: \")\n",
    "                    print(e)\n",
    "    return retval\n",
    "\n",
    "\n",
    "def pgquery(conn, sqlcmd, args, silent=False):\n",
    "    \"\"\" utility function to execute some SQL query statement\n",
    "        can take optional arguments to fill in (dictionary)\n",
    "        will print out on screen the result set of the query\n",
    "        error and transaction handling built-in \"\"\"\n",
    "    retval = False\n",
    "    result = []\n",
    "    with conn:\n",
    "        with conn.cursor() as cur:\n",
    "            try:\n",
    "                if args is None:\n",
    "                    cur.execute(sqlcmd)\n",
    "                else:\n",
    "                    cur.execute(sqlcmd, args)\n",
    "                if silent == False:\n",
    "                    for record in cur:\n",
    "                        result.append(record)\n",
    "                retval = True\n",
    "            except Exception as e:\n",
    "                if silent == False:\n",
    "                    print(\"db read error: \")\n",
    "                    print(e)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sql_setup.py\n",
    "\n",
    "# function that takes the data and if the value is empty, change it to NULL\n",
    "def clean_empty_string(data):\n",
    "    for row in data:\n",
    "        for key, value in row.items():\n",
    "            if value == \"\":\n",
    "                row[key] = None\n",
    "\n",
    "\n",
    "def create_table(file, queries):\n",
    "    data = list(csv.DictReader(open(file + '.csv')))\n",
    "    clean_empty_string(data)\n",
    "    # to reset table\n",
    "    pgexec(conn, \"DROP TABLE IF EXISTS \" + file, None, \"Reset Table \" + file)\n",
    "    # create table using schema\n",
    "    pgexec(conn, queries[0], None, \"Create Table \" + file)\n",
    "    # insert values to table\n",
    "    for row in data:\n",
    "        pgexec(conn, queries[1], row, \"row inserted\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # login to database\n",
    "    conn = pgconnect()\n",
    "\n",
    "    # =====Queries for creating and inserting table=====\n",
    "    business_stats_schema = \"\"\"CREATE TABLE IF NOT EXISTS BusinessStats (\n",
    "                                        area_id INT NOT NULL PRIMARY KEY,\n",
    "                                        num_businesses INT,\n",
    "                                        retail_trade INT,\n",
    "                                        accommodation_and_food_services INT,\n",
    "                                        health_care_and_social_assistance INT,\n",
    "                                        education_and_training INT,\n",
    "                                        arts_and_recreation_services INT\n",
    "                               )\"\"\"\n",
    "    business_stats_insert_stmt = \"\"\"INSERT INTO BusinessStats(\n",
    "                                            area_id,\n",
    "                                            num_businesses,\n",
    "                                            retail_trade,\n",
    "                                            accommodation_and_food_services,\n",
    "                                            health_care_and_social_assistance,\n",
    "                                            education_and_training,\n",
    "                                            arts_and_recreation_services)\n",
    "                                            VALUES (\n",
    "                                            %(area_id)s,\n",
    "                                            %(num_businesses)s,\n",
    "                                            %(retail_trade)s,\n",
    "                                            %(accommodation_and_food_services)s,\n",
    "                                            %(health_care_and_social_assistance)s,\n",
    "                                            %(education_and_training)s,\n",
    "                                            %(arts_and_recreation_services)s)\"\"\"\n",
    "\n",
    "    bike_pods_schema = \"\"\"CREATE TABLE IF NOT EXISTS BikeSharingPods(\n",
    "                            station_id INT NOT NULL PRIMARY KEY,\n",
    "                            name VARCHAR(70),\n",
    "                            num_bikes INT,\n",
    "                            num_scooters INT,\n",
    "                            latitude FLOAT,\n",
    "                            longitude FLOAT,\n",
    "                            description VARCHAR(500)\n",
    "                        )\"\"\"\n",
    "    bike_pods_insert_stmt = \"\"\"INSERT INTO BikeSharingPods(\n",
    "                                station_id,\n",
    "                                name,\n",
    "                                num_bikes,\n",
    "                                num_scooters,\n",
    "                                latitude,\n",
    "                                longitude,\n",
    "                                description)\n",
    "                                VALUES (\n",
    "                                %(station_id)s,\n",
    "                                %(name)s,\n",
    "                                %(num_bikes)s,\n",
    "                                %(num_scooters)s,\n",
    "                                %(latitude)s,\n",
    "                                %(longitude)s,\n",
    "                                %(description)s)\"\"\"\n",
    "\n",
    "    census_stats_schema = \"\"\"CREATE TABLE IF NOT EXISTS CensusStats(\n",
    "                                area_id INT NOT NULL PRIMARY KEY,\n",
    "                                median_annual_household_income INT,\n",
    "                                avg_monthly_rent INT\n",
    "                            )\"\"\"\n",
    "    census_stats_insert_stmt = \"\"\"INSERT INTO CensusStats(\n",
    "                                    area_id,\n",
    "                                    median_annual_household_income,\n",
    "                                    avg_monthly_rent)\n",
    "                                    VALUES (\n",
    "                                    %(area_id)s,\n",
    "                                    %(median_annual_household_income)s,\n",
    "                                    %(avg_monthly_rent)s)\"\"\"\n",
    "\n",
    "    neighbourhoods_schema = \"\"\"CREATE TABLE IF NOT EXISTS Neighbourhoods(\n",
    "                                area_id INT NOT NULL PRIMARY KEY,\n",
    "                                area_name VARCHAR(70),\n",
    "                                land_area FLOAT,\n",
    "                                population INT,\n",
    "                                number_of_dwellings INT,\n",
    "                                number_of_businesses INT\n",
    "                            )\"\"\"\n",
    "    neighbourhoods_insert_stmt = \"\"\"INSERT INTO Neighbourhoods(\n",
    "                                    area_id,\n",
    "                                    area_name,\n",
    "                                    land_area,\n",
    "                                    population,\n",
    "                                    number_of_dwellings,\n",
    "                                    number_of_businesses)\n",
    "                                    VALUES (\n",
    "                                    %(area_id)s,\n",
    "                                    %(area_name)s,\n",
    "                                    %(land_area)s,\n",
    "                                    %(population)s,\n",
    "                                    %(number_of_dwellings)s,\n",
    "                                    %(number_of_businesses)s)\"\"\"\n",
    "\n",
    "    statistical_areas_schema = \"\"\"CREATE TABLE IF NOT EXISTS StatisticalAreas(\n",
    "                                    area_id INT NOT NULL PRIMARY KEY,\n",
    "                                    area_name VARCHAR(70),\n",
    "                                    parent_area_id INT\n",
    "                                )\"\"\"\n",
    "    statistical_areas_insert_stmt = \"\"\"INSERT INTO StatisticalAreas(\n",
    "                                        area_id,\n",
    "                                        area_name,\n",
    "                                        parent_area_id)\n",
    "                                        VALUES (\n",
    "                                        %(area_id)s,\n",
    "                                        %(area_name)s,\n",
    "                                        %(parent_area_id)s)\"\"\"\n",
    "    # =====QUERIES END=====\n",
    "\n",
    "    #force drop and create schema\n",
    "    pgexec(conn, \"DROP SCHEMA IF EXISTS cyclability CASCADE;\", None, \"drop shema\")\n",
    "    pgexec(conn, \"CREATE SCHEMA cyclability;\", None, \"create schema\")\n",
    "\n",
    "    # Queries stored in key value pair, with file name as key, and queries stored as lists\n",
    "    queries = {\n",
    "        'BusinessStats': [business_stats_schema, business_stats_insert_stmt],\n",
    "        'BikeSharingPods': [bike_pods_schema, bike_pods_insert_stmt],\n",
    "        'CensusStats': [census_stats_schema, census_stats_insert_stmt],\n",
    "        'Neighbourhoods': [neighbourhoods_schema, neighbourhoods_insert_stmt],\n",
    "        'StatisticalAreas': [statistical_areas_schema, statistical_areas_insert_stmt]\n",
    "    }\n",
    "\n",
    "    # Loop through each file and queries to create a table\n",
    "    for k, v in queries.items():\n",
    "        create_table(k, v)\n",
    "    \n",
    "    #create indexes\n",
    "    pgexec(conn, \"CREATE INDEX land_area_idx ON neighbourhoods(land_area);\", None, \"create index on land area\")\n",
    "    pgexec(conn, \"CREATE INDEX num_businesses_idx ON businessstats(num_businesses)\", None, \"create index on business\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from postgis_enabling\n",
    "\n",
    "cmd = \"\"\"\n",
    "create extension IF NOT EXISTS postgis;\n",
    "\n",
    "create extension IF NOT EXISTS fuzzystrmatch;\n",
    "\n",
    "create extension IF NOT EXISTS postgis_tiger_geocoder;\n",
    "\n",
    "create extension IF NOT EXISTS postgis_topology;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# conn = pgconnect()\n",
    "pgexec(conn, cmd, None, \"enabling postgis\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scores.py\n",
    "\n",
    "def create_column(conn, col_name, table_name, type):\n",
    "    query = \"\"\"ALTER TABLE {}\n",
    "                DROP COLUMN IF EXISTS {}, \n",
    "                ADD COLUMN {} {};\"\"\".format(table_name, col_name, col_name, type)\n",
    "\n",
    "    pgexec(conn, query, None, \"Created Column \" + col_name + \" on \" + table_name)\n",
    "\n",
    "def update_column_with_another(conn, col_name, table_name, value):\n",
    "    query = \"\"\"UPDATE {}\n",
    "               SET {} = COALESCE{}\"\"\".format(table_name, col_name, value)\n",
    "\n",
    "    pgexec(conn, query, None, \"Update \" + col_name + \" on \" + table_name +\" with \" + value)\n",
    "\n",
    "def fix_NULL(item):\n",
    "    if (item == None):\n",
    "        return 0\n",
    "    \n",
    "    return item\n",
    "\n",
    "\n",
    "def update_service_balance(conn):\n",
    "    subquery = \"\"\"SELECT * FROM neighbourhoods JOIN businessstats USING (area_id);\"\"\"\n",
    "    result = pgquery(conn, subquery, None)\n",
    "\n",
    "    for row in result:\n",
    "\n",
    "        recreation = row[-1]\n",
    "        education = row[-2]\n",
    "        health = row[-3]\n",
    "        food = row[-4]\n",
    "        retail = row[-5]\n",
    "\n",
    "        recreation = fix_NULL(recreation)\n",
    "        education = fix_NULL(education)\n",
    "        food = fix_NULL(food)\n",
    "        retail = fix_NULL(retail)\n",
    "        health = fix_NULL(health)\n",
    "        \n",
    "        sum = recreation + education + health + food + retail\n",
    "        if (sum == 0):\n",
    "            continue\n",
    "        \n",
    "        service_balance = (education * 5 + food * 4 + retail * 3 + recreation * 2 + health) / sum\n",
    "\n",
    "        query = \"\"\"UPDATE neighbourhoods SET service_balance = {} WHERE area_id = {}\"\"\".format(service_balance, row[0])\n",
    "        pgexec(conn, query, None, \"Set service balance of area \" + str(row[0]) + \" to \" + str(service_balance))\n",
    "        \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     conn = pgconnect()\n",
    "\n",
    "create_column(conn, \"population_density\", \"neighbourhoods\", \"DOUBLE PRECISION\")\n",
    "create_column(conn, \"dwelling_density\", \"neighbourhoods\", \"DOUBLE PRECISION\")\n",
    "create_column(conn, \"service_balance\", \"neighbourhoods\", \"DOUBLE PRECISION\")\n",
    "create_column(conn, \"bikepod_density\", \"neighbourhoods\", \"DOUBLE PRECISION\")\n",
    "update_column_with_another(conn, \"population_density\", \"neighbourhoods\", \"(population / land_area)\")\n",
    "update_column_with_another(conn, \"dwelling_density\", \"neighbourhoods\", \"(number_of_dwellings / land_area)\")\n",
    "\n",
    "update_service_balance(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from geo_link.py\n",
    "\n",
    "sf = shapefile.Reader(\"1270055001_sa2_2016_aust_shape/SA2_2016_AUST.shp\", encoding=\"iso-8859-1\")\n",
    "# which shape type is it?\n",
    "print(sf)\n",
    "\n",
    "print(sf.fields)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(sf.record(i))\n",
    "\n",
    "# conn = pgconnect()\n",
    "create_column(conn, \"geom\", \"neighbourhoods\", \"GEOMETRY(Polygon, 4326)\")\n",
    "\n",
    "update_stmt = \"\"\"UPDATE neighbourhoods SET geom = ST_GEOMFROMTEXT(%(geom)s, 4326) WHERE area_id = %(area_id)s;\"\"\"\n",
    "\n",
    "shapes = sf.shapes()\n",
    "records= sf.records()\n",
    "\n",
    "\n",
    "areas = pgquery(conn, \"SELECT area_id FROM neighbourhoods;\", \"Find existing areas\")\n",
    "\n",
    "area_ids = []\n",
    "for r in areas:\n",
    "    area_ids.append(r[0])\n",
    "\n",
    "\n",
    "row = {}\n",
    "for i in range(0, len(shapes)):\n",
    "    record = sf.record(i)\n",
    "\n",
    "    if int(record[0]) in area_ids:\n",
    "        shape  = sf.shape(i)\n",
    "\n",
    "        row['area_id']=record[0]\n",
    "        \n",
    "        # prepare the polygon data\n",
    "        # this is a bit complex with our dataset as it has complex polygons, some with multiple parts...\n",
    "        row['geom']=\"POLYGON((\"\n",
    "        i=0\n",
    "        for x, y in shape.points:\n",
    "            row['geom']+=\"%s %s,\" % (x,y)\n",
    "            # check for start of a new polygon part\n",
    "            i += 1\n",
    "            if i in shape.parts:\n",
    "                row['geom']= re.sub(\",$\", \"),(\", row['geom'])\n",
    "        # properly end the polygon string\n",
    "        row['geom'] = re.sub(\",$\", \"))\", row['geom'])\n",
    "        \n",
    "        # finally: insert new row into the table\n",
    "        pgexec(conn, update_stmt, args=row, msg=\"inserted \"+str(record[2]))\n",
    "\n",
    "index_command = \"CREATE INDEX area_idx ON neighbourhoods USING GIST (geom);\"\n",
    "pgexec(conn, index_command, None, \"Created spatial index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from allocate_bikepods.py\n",
    "\n",
    "create_column(conn, \"geom\", \"bikesharingpods\", \"geometry(POINT, 4326);\")\n",
    "pgexec(conn, \"update bikesharingpods set geom=st_SetSrid(st_MakePoint(longitude, latitude), 4326);\", None, \"\")\n",
    "pgexec(conn, \"CREATE INDEX IF NOT EXISTS bike_geo_idx ON bikesharingpods USING GIST(geom);\", None, \"Creating bike geo index\")\n",
    "\n",
    "\n",
    "update_stmt = \"\"\"UPDATE neighbourhoods N2 SET bikepod_density = \n",
    "                ((SELECT COUNT(name) FROM bikesharingpods B JOIN neighbourhoods N ON (ST_CONTAINS(N.geom, B.geom)) WHERE N2.area_id = N.area_id) / N2.land_area)\"\"\"\n",
    "\n",
    "pgexec(conn, update_stmt, None, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from z_score.py\n",
    "\n",
    "def fix_NULL(item):\n",
    "    if (item == None):\n",
    "        return 0\n",
    "    \n",
    "    return item\n",
    "\n",
    "create_column(conn, \"cyclability_score\", \"neighbourhoods\", \"DOUBLE PRECISION\")\n",
    "\n",
    "avg_pd = pgquery(conn, \"SELECT AVG(population_density) FROM neighbourhoods;\", None)\n",
    "avg_dd = pgquery(conn, \"SELECT AVG(dwelling_density) FROM neighbourhoods;\", None)\n",
    "avg_sb = pgquery(conn, \"SELECT AVG(service_balance) FROM neighbourhoods;\", None)\n",
    "avg_bd = pgquery(conn, \"SELECT AVG(bikepod_density) FROM neighbourhoods;\", None)\n",
    "\n",
    "std_pd = pgquery(conn, \"SELECT STDDEV(population_density) FROM neighbourhoods;\", None)\n",
    "std_dd = pgquery(conn, \"SELECT STDDEV(dwelling_density) FROM neighbourhoods;\", None)\n",
    "std_sb = pgquery(conn, \"SELECT STDDEV(service_balance) FROM neighbourhoods;\", None)\n",
    "std_bd = pgquery(conn, \"SELECT STDDEV(bikepod_density) FROM neighbourhoods;\", None)\n",
    "\n",
    "avg_pd = float(avg_pd[0][0])\n",
    "avg_dd = float(avg_dd[0][0])\n",
    "avg_sb = float(avg_sb[0][0])\n",
    "avg_bd = float(avg_bd[0][0])\n",
    "\n",
    "std_pd = float(std_pd[0][0])\n",
    "std_dd = float(std_dd[0][0])\n",
    "std_sb = float(std_sb[0][0])\n",
    "std_bd = float(std_bd[0][0])\n",
    "\n",
    "print(avg_pd)\n",
    "result = pgquery(conn, \"SELECT * FROM neighbourhoods\", None)\n",
    "\n",
    "def additional_score():\n",
    "    return 0\n",
    "\n",
    "for row in result:\n",
    "    z_score = (float(fix_NULL(row[-3])) - avg_bd) / std_bd\n",
    "    z_score += (float(fix_NULL(row[-4])) - avg_sb) / std_sb\n",
    "    z_score += (float(fix_NULL(row[-5])) - avg_dd) / std_dd\n",
    "    z_score += (float(fix_NULL(row[-6])) - avg_pd) / std_pd\n",
    "    z_score += additional_score()\n",
    "\n",
    "    query = \"UPDATE neighbourhoods SET cyclability_score = {} WHERE area_id = {}\".format(z_score, row[0])\n",
    "    pgexec(conn, query, None, \"Updating score for {}\".format(row[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from correlation.py\n",
    "\n",
    "result = pgquery(conn, \"SELECT * FROM neighbourhoods JOIN censusstats USING (area_id) ORDER BY area_id;\", None)\n",
    "z_score = []\n",
    "income = []\n",
    "rent = []\n",
    "for row in result:\n",
    "    z_score.append(row[-3])\n",
    "    income.append(row[-2])\n",
    "    rent.append(row[-1])\n",
    "\n",
    "score_income = pd.DataFrame({\"score\": z_score, \"income\": income})\n",
    "score_rent = pd.DataFrame({\"score\": z_score, \"rent\": rent})\n",
    "\n",
    "plt.figure()\n",
    "plot1 = sb.regplot(x = \"score\", y= \"income\", data = score_income, fit_reg = False)\n",
    "fig1 = plot1.get_figure()\n",
    "fig1.savefig(\"score_income\")\n",
    "\n",
    "plt.figure()\n",
    "plot2 = sb.regplot(x = \"score\", y = \"rent\", data = score_rent, fit_reg = False)\n",
    "fig2 = plot2.get_figure()\n",
    "fig2.savefig(\"score_rent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT geom, cyclability_score FROM neighbourhoods;\"\n",
    "gpd_df = gpd.GeoDataFrame.from_postgis(query, conn, geom_col='geom')\n",
    "\n",
    "query = \"SELECT MAX(cyclability_score), MIN(cyclability_score) FROM neighbourhoods;\"\n",
    "result = pgquery(conn, query, None)\n",
    "v_max = result[0][0]\n",
    "v_min = result[0][1]\n",
    "fig1, ax = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "plt.figure()\n",
    "plot1 = gpd_df.plot(column = \"cyclability_score\", cmap = \"Blues\", linewidth = 0.8, ax = ax, edgecolor = '0.8')\n",
    "plot1.axis(\"off\")\n",
    "plot1.set_title(\"Cyclability Score in Sydney\", fontdict={\"fontsize\": \"14\", \"fontweight\" : \"2\"})\n",
    "\n",
    "fig1 = plot1.get_figure()\n",
    "sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=plt.Normalize(vmin=v_min, vmax=v_max))\n",
    "sm._A = []\n",
    "fig1.colorbar(sm)\n",
    "fig1.savefig(\"map_overlay\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
